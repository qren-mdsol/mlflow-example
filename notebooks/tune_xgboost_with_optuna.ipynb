{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd20caa4",
   "metadata": {
    "title": "Imports"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dblickstein/Projects/mlflow-example/mlflow-example-wwba5rmb-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import yaml\n",
    "import mlflow\n",
    "import optuna   \n",
    "import os\n",
    "\n",
    "from importlib import reload\n",
    "import utils as u\n",
    "from visualization_helpers import plot_residuals, plot_xgb_feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c434000",
   "metadata": {
    "title": "Set Experiment Configuration"
   },
   "outputs": [],
   "source": [
    "experiment_id = u.get_or_create_experiment(\"Apples Demand\")\n",
    "mlflow.set_experiment(experiment_id=experiment_id)\n",
    "run_name = \"xgboost_optuna\"\n",
    "\n",
    "with open(\"config/xgboost_optuna.yaml\") as f:\n",
    "    xgb_config = yaml.load(f,Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f9d4300",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Preprocess Data"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data/apple-sales.csv\")\n",
    "\n",
    "X = df.drop(columns=[\"date\", \"demand\"])\n",
    "y = df[\"demand\"]\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size=0.25)\n",
    "dtrain = xgb.DMatrix(train_x, label=train_y)\n",
    "dvalid = xgb.DMatrix(valid_x, label=valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfafa82b",
   "metadata": {
    "title": "Specify Objective function"
   },
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial:optuna.Trial):\n",
    "\n",
    "    # Define hyperparameters\n",
    "    search_grid=xgb_config['search_grid']\n",
    "    params = {\n",
    "        \"objective\": xgb_config['objective'],\n",
    "        \"eval_metric\": xgb_config['eval_metric'],\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", search_grid['booster']),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", \n",
    "                                      *search_grid['lambda_range'],\n",
    "                                      log=True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", *search_grid['alpha_range'],log=True),\n",
    "    }\n",
    "    if params['booster'] in ['gbtree','dart']:\n",
    "        params[\"max_depth\"] = trial.suggest_int(\"max_depth\",*search_grid['max_depth_range'])\n",
    "        params[\"eta\"] = trial.suggest_float(\"eta\",\n",
    "                                            search_grid['eta_range'][0],\n",
    "                                            search_grid['eta_range'][1], \n",
    "                                            log=True)\n",
    "        params[\"gamma\"] = trial.suggest_float(\"gamma\",\n",
    "                                              *search_grid['gamma_range'],\n",
    "                                                log=True)\n",
    "        params[\"grow_policy\"] = trial.suggest_categorical(\n",
    "            \"grow_policy\", search_grid['grow_policy']\n",
    "        )\n",
    "    child_run_name=u.convert_params_to_string(params)\n",
    "    with mlflow.start_run(run_name=child_run_name,nested=True):\n",
    "        # Train XGBoost model\n",
    "        train_start=time.time()\n",
    "        bst = xgb.train(params, dtrain)\n",
    "        train_finish=time.time()\n",
    "        train_time_seconds=train_finish-train_start\n",
    "        \n",
    "        preds = bst.predict(dvalid)\n",
    "        eval_metrics=u.evaluate_regression_metrics(valid_y,preds)\n",
    "        error_score=eval_metrics['rmse']\n",
    "        \n",
    "        # Log to MLflow\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics(eval_metrics)\n",
    "        mlflow.log_metric(\"train_time_seconds\", train_time_seconds)\n",
    "\n",
    "        return error_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8546926",
   "metadata": {
    "title": "Tune and Retrain Best Params"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initiate the parent run and call the hyperparameter tuning child run logic\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name=run_name, nested=True):\n",
    "    # Initialize the Optuna study\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "\n",
    "    # Execute the hyperparameter optimization trials.\n",
    "    # Note the addition of the `champion_callback` inclusion to control our logging\n",
    "    study.optimize(objective, n_trials=xgb_config['ntrial'])\n",
    "\n",
    "    mlflow.log_params(study.best_params)\n",
    "    mlflow.log_metric(\"best_rmse\", study.best_value)\n",
    "\n",
    "    # Log tags\n",
    "    mlflow.set_tags(\n",
    "        tags={\n",
    "            \"project\": \"Apple Demand Project\",\n",
    "            \"optimizer_engine\": \"optuna\",\n",
    "            \"model_family\": \"xgboost\",\n",
    "            \"feature_set_version\": 1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # retrain\n",
    "    model = xgb.train(study.best_params, dtrain)\n",
    "    preds=model.predict(dvalid)\n",
    "    eval_metrics=u.evaluate_regression_metrics(valid_y,preds)\n",
    "    mlflow.log_metrics(eval_metrics)\n",
    "\n",
    "    # Log the feature importances plot\n",
    "    importances = plot_xgb_feature_importance(model, booster=study.best_params.get(\"booster\"))\n",
    "    mlflow.log_figure(figure=importances, artifact_file=\"feature_importances.png\")\n",
    "\n",
    "    # Log the residuals plot\n",
    "    residuals = plot_residuals(valid_y,preds)\n",
    "    mlflow.log_figure(figure=residuals, artifact_file=\"residuals.png\")\n",
    "\n",
    "    artifact_path = \"xgboost_optuna_model\"\n",
    "\n",
    "    mlflow.xgboost.log_model(\n",
    "        xgb_model=model,\n",
    "        artifact_path=artifact_path,\n",
    "        input_example=train_x.iloc[[0]],\n",
    "        model_format=\"ubj\",\n",
    "        metadata={\"model_data_version\": 1},\n",
    "    )\n",
    "    model_uri = mlflow.get_artifact_uri(artifact_path)\n",
    "    \n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0451e321",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Predict From Loaded Model"
   },
   "outputs": [],
   "source": [
    "loaded = mlflow.xgboost.load_model(model_uri)    \n",
    "batch_dmatrix = xgb.DMatrix(X)\n",
    "inference = loaded.predict(batch_dmatrix)\n",
    "infer_df = df.copy()\n",
    "infer_df[\"predicted_demand\"] = inference\n",
    "infer_df.head()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "mlflow-example-wwba5rmb-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
